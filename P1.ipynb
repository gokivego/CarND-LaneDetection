{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"\n",
    "    Converts a 3 color channel into grayscale image\n",
    "    mpimg reads image in RGB format whereas the\n",
    "    image if read with cv2 is in BGR format so,\n",
    "    we need to use the appropriate function.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(img,cv2.COLOR_RGB2GRAY) # Since initially we read the image using mpimg\n",
    "    # return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # if the image is read using cv2\n",
    "        \n",
    "def region_of_interest(img,vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "\n",
    "    This is done by creating a polygon with the given vertices and then\n",
    "    filling the polygon with the color white. When a bitwise_and operator is\n",
    "    applied on the image and the mask then only that part of the image is \n",
    "    retained that is desired.\n",
    "\n",
    "    Example \n",
    "    Using region_of_interest function\n",
    "    vertices = np.array(([0,200],[1000,200],[1000,600],[10,600]))\n",
    "    vertices = vertices.reshape((-1,1,2))\n",
    "    plt.imshow(region_of_interest(image,[vertices]))\n",
    "    \n",
    "    The region of interest typically lies between the mid region of the image to the bottom of the image. For\n",
    "    a specific camera angle the region of interest is already defined.\n",
    "    So while giving vertices its better to keep this point in view.\n",
    "    \"\"\"\n",
    "\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    # returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def equalized_Histogram(img):\n",
    "    \"\"\"\n",
    "    Processes the image for contrast.\n",
    "    Improves the contrast of the image that is dull.\n",
    "    It uses a technique called histogram equalization\n",
    "    \"\"\"\n",
    "    return cv2.equalizeHist(img)\n",
    "\n",
    "def gaussian_blur(img,kernel_size):\n",
    "    \"\"\"\n",
    "    Applies a Gaussian Noise Kernel.\n",
    "    The kernel_size has to be an odd number\n",
    "    The output is a blurred image with reduced noise\n",
    "    Changing the kernel size reduces or increases the noise but there is also a trade off. \n",
    "    \"\"\"\n",
    "    return cv2.GaussianBlur(img,(kernel_size,kernel_size),0)\n",
    "\n",
    "def adaptiveThreshold(img,maxValue,adaptiveMethod,thresholdType,blockSize,C):\n",
    "    \"\"\"\n",
    "    src – Source 8-bit single-channel image.\n",
    "    maxValue – Non-zero value assigned to the pixels for which the condition is satisfied. See the details below.\n",
    "    adaptiveMethod – Adaptive thresholding algorithm to use, ADAPTIVE_THRESH_MEAN_C or ADAPTIVE_THRESH_GAUSSIAN_C .\n",
    "    thresholdType – Thresholding type that must be either THRESH_BINARY or THRESH_BINARY_INV .\n",
    "    blockSize – Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on.\n",
    "    C – Constant subtracted from the mean or weighted mean (see the details below). Normally, it is positive but may be zero or negative as well.\n",
    "    \"\"\"\n",
    "    return cv2.adaptiveThreshold(img,maxValue,adaptiveMethod,thresholdType,blockSize,C)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=4):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to\n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).\n",
    "\n",
    "    Think about things like separating line segments by their\n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of\n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "\n",
    "    This function draws `lines` with `color` and `thickness`.\n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "\n",
    "def hough_lines(img, rho, theta, threshold,min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "\n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho,theta, threshold,np.array([]),\n",
    "                            minLineLength= min_line_len ,maxLineGap= max_line_gap) \n",
    "                        \n",
    "    \"\"\"\n",
    "    The lines files is of the shape (n,1,4) - where 4 represents points [x1,y1,x2,y2]. \n",
    "    Line is drawn from (x1,y1) to (x2,y2)\n",
    "    \"\"\"\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    \"\"\"\n",
    "    line_img generates a black screen the size of the original image. Now Hough lines are drawn on this\n",
    "    We need to use the weighted_img function to superimpose this image on the original image\n",
    "    \"\"\"\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img, lines \n",
    "#     return lines\n",
    "\n",
    "def weighted_img(img, initial_img,weighted_alpha=0.8, weighted_beta=1., weighted_lamda=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "\n",
    "    `initial_img` should be the image before any processing.\n",
    "\n",
    "    The result image is computed as follows:\n",
    "\n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(img,initial_img, weighted_alpha,weighted_beta, weighted_lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class find_lanes(object):\n",
    " \n",
    "    def __init__(self,image,kernel_size = 5,\n",
    "                 color =[255,0,0],\n",
    "                 thickness = 10,\n",
    "                 canny_low = 65,\n",
    "                 canny_high = 195,\n",
    "                 hough_rho = 1,\n",
    "                 hough_theta = np.pi/180, \n",
    "                 hough_threshold = 5,\n",
    "                 hough_min_line_len = 10, \n",
    "                 hough_max_line_gap = 5,\n",
    "                 weighted_alpha = 0.8,\n",
    "                 weighted_beta = 1.,\n",
    "                 weighted_lamda = 0.):\n",
    "        \n",
    "        self.orig_image = image\n",
    "        self.processed_image = np.copy(self.orig_image)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.color = color\n",
    "        self.thickness = thickness\n",
    "        self.canny_low = canny_low\n",
    "        self.canny_high = canny_high\n",
    "        self.hough_rho = hough_rho\n",
    "        self.hough_theta = hough_theta\n",
    "        self.hough_threshold = hough_threshold\n",
    "        self.hough_min_line_len = hough_min_line_len\n",
    "        self.hough_max_line_gap = hough_max_line_gap\n",
    "        self.weighted_alpha = weighted_alpha\n",
    "        self.weighted_beta = weighted_beta\n",
    "        self.weighted_lamda = weighted_lamda\n",
    "        \n",
    "        \n",
    "    def isolate_yellow_white(self):\n",
    "        \"\"\"\n",
    "        This function isolates the yellow lines in the image by converting the RGB image to HSV image\n",
    "        and isolating the yellow lines, it could also be used to isolate white lines in the image as well.\n",
    "        \"\"\"\n",
    "        img_hsv = cv2.cvtColor(self.processed_image, cv2.COLOR_RGB2HSV)\n",
    "        lower_yellow = np.array([20,100,100],dtype=np.uint8)\n",
    "        upper_yellow = np.array([40,255,255],dtype=np.uint8)\n",
    "        \n",
    "#         lower_white = np.array([0,0,0],dtype=np.uint8)\n",
    "#         upper_white = np.array([255,5,255],dtype=np.uint8)\n",
    "\n",
    "        mask_yellow = cv2.inRange(img_hsv, lower_yellow, upper_yellow) # Isolate yellow\n",
    "#         mask_white = cv2.inRange(img_hsv, lower_white, upper_white) # Isolate white\n",
    "        \n",
    "        mask_yellow = cv2.cvtColor(mask_yellow, cv2.COLOR_GRAY2RGB)\n",
    "#         mask_white = cv2.cvtColor(mask_white, cv2.COLOR_GRAY2RGB)\n",
    "#         isolated_image = cv2.bitwise_or(mask_white, self.processed_image)\n",
    "#         isolated_image = cv2.bitwise_or(mask_yellow, isolated_image)\n",
    "        return cv2.bitwise_or(mask_yellow, self.processed_image)\n",
    "#         plt.imshow(isolated_image)\n",
    "#         return isolated_image\n",
    "\n",
    "    def pre_process_image(self):\n",
    "        \n",
    "#         plt.subplots(nrows =3, ncols = 3)\n",
    "#         plt.tight_layout()\n",
    "        \n",
    "#         plt.subplot(331)\n",
    "#         plt.title('Original Image')\n",
    "#         plt.imshow(self.processed_image)\n",
    "        \n",
    "        self.processed_image = self.isolate_yellow_white()\n",
    "#         mpimg.imsave('images_for_writeup/isolated_yellow.jpg', self.processed_image)\n",
    "#         plt.subplot(332)\n",
    "#         plt.title('Yellow Isolated Image')\n",
    "#         plt.imshow(self.processed_image)\n",
    "        \n",
    "        self.processed_image = grayscale(self.processed_image)\n",
    "#         mpimg.imsave('images_for_writeup/grayscale.jpg', self.processed_image, cmap= 'gray')\n",
    "#         plt.subplot(333)\n",
    "#         plt.title('Grayscale Image')\n",
    "#         plt.imshow(self.processed_image, cmap= 'gray')\n",
    "        \n",
    "        self.processed_image = gaussian_blur(self.processed_image, self.kernel_size)\n",
    "#         mpimg.imsave('images_for_writeup/gaussian_blurred.jpg', self.processed_image, cmap = 'gray')\n",
    "\n",
    "#         plt.subplot(334)\n",
    "#         plt.title('Gaussian Blurred Image')\n",
    "#         plt.imshow(self.processed_image, cmap = 'gray')        \n",
    "        \n",
    "    def find_line_eq(self,lines):\n",
    "        \"\"\"\n",
    "        This function finds the lanes from a set of points. Since the argument that is passed to \n",
    "        this function lines is a bunch of points, all the function does is calculates the least squares\n",
    "        regression line made by the points\n",
    "        \"\"\"\n",
    "        # linear regression least squares alogrithm\n",
    "        # https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html\n",
    "        lines_array = np.asarray(lines)\n",
    "        x = np.reshape(lines_array[:, [0, 2]], (1, len(lines) * 2))[0]\n",
    "        y = np.reshape(lines_array[:, [1, 3]], (1, len(lines) * 2))[0]\n",
    "        A = np.vstack([x, np.ones(len(x))]).T\n",
    "        m,c = np.linalg.lstsq(A, y)[0]\n",
    "        x = np.array(x)\n",
    "        y = np.array(x*m + c)\n",
    "        return x, y, m, c\n",
    "\n",
    "        \n",
    "    def find_vertices(self):\n",
    "        \"\"\"\n",
    "        This functions helps define the vertices for the region of the lines that we are interested in\n",
    "        \"\"\"\n",
    "        height, width,_ = self.orig_image.shape\n",
    "        lower_left_vertex = [0.20*width,0.9*height]\n",
    "        upper_left_vertex = [0.43*width,0.6*height]\n",
    "        upper_right_vertex = [0.57*width,0.6*height]\n",
    "        lower_right_vertex = [0.90*width,0.9*height]\n",
    "        self.vertices = np.array([lower_left_vertex,upper_left_vertex,upper_right_vertex,lower_right_vertex], np.int32)\n",
    "        \n",
    "    def find_lines(self):\n",
    "        \"\"\"\n",
    "        This function does all the pre-processing steps to feed the processed image into hough_lines\n",
    "        \"\"\"\n",
    "        # Does all the pre-processing steps\n",
    "        self.pre_process_image()\n",
    "        \n",
    "        self.processed_image = canny(self.processed_image, self.canny_low, self.canny_high)\n",
    "#         mpimg.imsave('images_for_writeup/canny_image.jpg', self.processed_image, cmap = 'gray')\n",
    "\n",
    "#         plt.subplot(335)\n",
    "#         plt.title('Canny Image')\n",
    "#         plt.imshow(self.processed_image, cmap = 'gray')\n",
    "        \n",
    "        self.find_vertices()\n",
    "        self.processed_image = region_of_interest(self.processed_image, [self.vertices])\n",
    "#         mpimg.imsave('images_for_writeup/region_of_interest.jpg', self.processed_image, cmap = 'gray')\n",
    "\n",
    "#         plt.subplot(336)\n",
    "#         plt.title('Region of Interest')\n",
    "#         plt.imshow(self.processed_image, cmap = 'gray')\n",
    "        \n",
    "        \n",
    "        self.hough_image, self.lines = hough_lines(self.processed_image,\n",
    "                                        self.hough_rho,\n",
    "                                        self.hough_theta,\n",
    "                                        self.hough_threshold,\n",
    "                                        self.hough_min_line_len,\n",
    "                                        self.hough_max_line_gap )\n",
    "\n",
    "#         mpimg.imsave('images_for_writeup/hough_image.jpg',self.hough_image, cmap = 'gray')\n",
    "        \n",
    "        \n",
    "        self.processed_image = cv2.bitwise_or(self.hough_image,\n",
    "                                            self.orig_image)\n",
    "        \n",
    "#         mpimg.imsave('images_for_writeup/superimposed_hough_image.jpg',self.processed_image)\n",
    "\n",
    "#         self.hough = np.copy(self.hough_image)\n",
    "#         self.hough = region_of_interest(self.hough, [self.vertices])\n",
    "#         plt.imshow(self.processed_image)\n",
    "        \n",
    "    def find_slopes(self):\n",
    "        self.slope = []\n",
    "        for line in self.lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                self.slope.append((y2-y1)/(x2-x1))\n",
    "        \n",
    "    def draw_extrapolated_lines(self):\n",
    "        \n",
    "        self.find_lines()\n",
    "        \n",
    "        # Approach 2 - Using The least squares regression line to find extrapolated lines\n",
    "        \n",
    "        left_x_y_values = []\n",
    "\n",
    "        right_x_y_values = []\n",
    "\n",
    "        self.upper_y = self.processed_image.shape[0]\n",
    "        self.lower_y = self.processed_image.shape[0]\n",
    "        \n",
    "        center_x = int(self.processed_image.shape[1]*0.5)\n",
    "\n",
    "        for line in self.lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                slope = (y2-y1)/(x2-x1)\n",
    "                self.upper_y = min(self.upper_y, y1, y2)\n",
    "                \n",
    "                #slope,intercept = np.polyfit((x1,x2),(y1,y2),1)\n",
    "                if (slope < -0.4 and slope > -0.8 and x1 < center_x and x2 < center_x):\n",
    "                    left_x_y_values.append([x1,y1,x2,y2])\n",
    "                elif (slope > 0.4 and slope <0.8 and x1 > center_x and x2 > center_x):\n",
    "                    right_x_y_values.append([x1,y1,x2,y2])\n",
    "        \n",
    "         \n",
    "        left_line_x, left_line_y, left_line_slope, left_line_intercept = self.find_line_eq(left_x_y_values)\n",
    "\n",
    "        right_line_x, right_line_y, right_line_slope, right_line_intercept = self.find_line_eq(right_x_y_values)\n",
    "        \n",
    "        #print (\"left intercept = \",left_line_intercept, \"right line intercept = \", right_line_intercept)\n",
    "        #right_line_intercept = min(right_line_intercept, 0)\n",
    "        \n",
    "        lower_left_point = np.array([(self.lower_y - left_line_intercept)/left_line_slope,self.lower_y], dtype= int)\n",
    "        lower_right_point = np.array([(self.lower_y - right_line_intercept)/right_line_slope,self.lower_y], dtype= int)\n",
    "        upper_left_point = np.array([(self.upper_y - left_line_intercept)/left_line_slope,self.upper_y], dtype= int)\n",
    "        upper_right_point = np.array([(self.upper_y - right_line_intercept)/right_line_slope,self.upper_y], dtype= int)\n",
    "        \n",
    "        line_image = np.zeros_like(self.orig_image)\n",
    "        cv2.line(line_image,(lower_left_point[0],lower_left_point[1]), \n",
    "                 (upper_left_point[0],upper_left_point[1]), \n",
    "                 self.color, \n",
    "                 self.thickness)\n",
    "        \n",
    "        cv2.line(line_image,(lower_right_point[0],lower_right_point[1]), \n",
    "                 (upper_right_point[0],upper_right_point[1]), \n",
    "                 self.color, \n",
    "                 self.thickness)\n",
    "        \n",
    "#         cv2.line(line_image,(center_x,self.lower_y),(center_x,self.upper_y), self.color, 5)\n",
    "        \n",
    "#         plt.subplots(1,2)\n",
    "#         plt.subplot(121)\n",
    "#         plt.imshow(line_image)\n",
    "        \n",
    "        self.final_image = cv2.bitwise_or(line_image, self.orig_image)\n",
    "#         mpimg.imsave('images_for_writeup/final_image.jpg', self.final_image)\n",
    "\n",
    "#        self.final_image = region_of_interest(self.final_image, vertices = [self.vertices])\n",
    "        \n",
    "        \n",
    "#         plt.subplot(122)\n",
    "#         plt.imshow(self.final_image)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Image Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_test_images(inp_dir, out_dir):\n",
    "    files = os.listdir(inp_dir)\n",
    "    for file in files:\n",
    "        print ('Processing image file - ',file)\n",
    "        image_pipeline(file, out_dir)\n",
    "        \n",
    "def image_pipeline(file, out_dir):\n",
    "    image = mpimg.imread('test_images/'+ file)\n",
    "    img = find_lanes(image)\n",
    "    img.draw_extrapolated_lines()\n",
    "    mpimg.imsave(out_dir + file ,img.final_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Video part using moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    lane_find = find_lanes(image)\n",
    "    lane_find.draw_extrapolated_lines()\n",
    "    return lane_find.final_image\n",
    "\n",
    "def process_video_file(inp_video, out_video):\n",
    "    print ('------------------------Processing Video - ' + inp_video + ' ---------------------------')\n",
    "    output_file = out_video\n",
    "    clip1 = VideoFileClip(inp_video)\n",
    "    white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "    white_clip.write_videofile(output_file, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    process_test_images('test_images/', 'processed_images/')\n",
    "    process_video_file(\"solidWhiteRight.mp4\", \"white.mp4\")\n",
    "    process_video_file(\"solidYellowLeft.mp4\", \"yellow.mp4\")\n",
    "    process_video_file(\"challenge.mp4\", \"extra.mp4\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [carnd-term1]",
   "language": "python",
   "name": "Python [carnd-term1]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
